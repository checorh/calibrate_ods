{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sumo_python.helpers.load_experiment_metadata import load_experiment_config\n",
    "\n",
    "input_path = \"/Users/rodrse/Documents/DemandCalibration/notebooks/od_calibration_sumo_files/\"\n",
    "\n",
    "config, sim_setup = load_experiment_config(config=input_path + 'config.json',\n",
    "                        sim_setup=input_path + 'simulation_setups.json',)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "od2trips --no-step-log  --spread.uniform --taz-files /Users/rodrse/Documents/DemandCalibration/notebooks/od_calibration_sumo_files/quickstart/data/quickstart.taz.xml --tazrelation-files /Users/rodrse/Documents/DemandCalibration/notebooks/od_calibration_sumo_files/quickstart/data/quickstart.gt_od.xml -o /Users/rodrse/Documents/DemandCalibration/notebooks/od_calibration_sumo_files/quickstart/data/gt_od_trips.trips.xml \n",
      "Success.\n",
      "sumo --output-prefix gt_ --ignore-route-errors=true --net-file=/Users/rodrse/Documents/DemandCalibration/notebooks/od_calibration_sumo_files/quickstart/data/quickstart.net.xml --routes=/Users/rodrse/Documents/DemandCalibration/notebooks/od_calibration_sumo_files/quickstart/data/gt_od_trips.trips.xml -b 54000 -e 57600 --additional-files /Users/rodrse/Documents/DemandCalibration/notebooks/od_calibration_sumo_files/quickstart/data/quickstart.additional.xml --duration-log.statistics --xml-validation never --vehroutes /Users/rodrse/Documents/DemandCalibration/notebooks/od_calibration_sumo_files/quickstart/data/gt_routes.vehroutes.xml \n",
      "Loading net-file from '/Users/rodrse/Documents/DemandCalibration/notebooks/od_calibration_sumo_files/quickstart/data/quickstart.net.xml' ... done (10ms).\n",
      "Loading additional-files from '/Users/rodrse/Documents/DemandCalibration/notebooks/od_calibration_sumo_files/quickstart/data/quickstart.additional.xml' ... done (2ms).\n",
      "Loading done.\n",
      "Simulation version 1.16.0 started with time: 54000.00.\n",
      "Step #57600.00 (9ms ~= 111.11*RT, ~72888.89UPS, vehicles TOT 2800 ACT 656 BUF 0)          \n",
      "Simulation ended at time: 57600.00\n",
      "Reason: The final simulation step has been reached.\n",
      "Performance: \n",
      " Duration: 16.02s\n",
      " Real time factor: 224.733\n",
      " UPS: 100953.992134\n",
      "Vehicles: \n",
      " Inserted: 2800\n",
      " Running: 656\n",
      " Waiting: 0\n",
      "Statistics (avg of 2144):\n",
      " RouteLength: 4392.77\n",
      " Speed: 11.24\n",
      " Duration: 471.78\n",
      " WaitingTime: 81.10\n",
      " TimeLoss: 153.11\n",
      " DepartDelay: 0.10\n",
      "\n",
      "DijkstraRouter answered 2800 queries and explored 10.01 edges on average.\n",
      "DijkstraRouter spent 0.01s answering queries (0.00ms on average).\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from sumo_python.helpers.generate_od_xml import generate_od_xml\n",
    "from sumo_python.simulator.run_sumo_and_parse_output import run_sumo_and_parse_output\n",
    "from sumo_python.simulator.ground_truth import run_ground_truth_and_parse\n",
    "from sumo_python.helpers.nrmse_counts import compute_nrmse_counts\n",
    "\n",
    "df_gt_data = run_ground_truth_and_parse(config, sim_setup)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### BO with BAxUS and TS/EI\n",
    "Weimplement Bayesian optimization with adaptively expanding subspaces (BAxUS) in a closed loop in BoTorch. This is purposefully similar to the TuRBO tutorial to highlight the differences in the implementations.\n",
    "\n",
    "Source: https://botorch.org/tutorials/baxus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running on cpu\n"
     ]
    }
   ],
   "source": [
    "import math\n",
    "import os\n",
    "from dataclasses import dataclass\n",
    "\n",
    "import botorch\n",
    "import gpytorch\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import torch\n",
    "from gpytorch.constraints import Interval\n",
    "from gpytorch.kernels import MaternKernel, ScaleKernel\n",
    "from gpytorch.likelihoods import GaussianLikelihood\n",
    "from gpytorch.mlls import ExactMarginalLogLikelihood\n",
    "from torch.quasirandom import SobolEngine\n",
    "\n",
    "from botorch.acquisition.analytic import ExpectedImprovement\n",
    "from botorch.exceptions import ModelFittingError\n",
    "from botorch.fit import fit_gpytorch_mll\n",
    "from botorch.generation import MaxPosteriorSampling\n",
    "from botorch.models import SingleTaskGP\n",
    "from botorch.optim import optimize_acqf\n",
    "from botorch.test_functions import Branin\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Running on {device}\")\n",
    "dtype = torch.double\n",
    "SMOKE_TEST = os.environ.get(\"SMOKE_TEST\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "def objective(x: np.array) -> pd.DataFrame:\n",
    "    \"\"\"Compute objective variable. This is the NRMSE loss between ground-truth output\n",
    "    and the output of the simulation output evaluated at x.\n",
    "\n",
    "    Args:\n",
    "        x (np.array): Numpy array of counts to generate TAZ file from.\n",
    "\n",
    "    Returns:\n",
    "        pd.Dataframe: Data frame of sampling locations and loss esimate.\n",
    "    \"\"\"\n",
    "    prefix_run = 'iter'    \n",
    "    generate_od_xml(x, config, sim_setup, prefix_run)\n",
    "    df_simulated = run_sumo_and_parse_output(config, sim_setup, prefix_run)\n",
    "    loss_estimate = compute_nrmse_counts(df_gt_data, df_simulated)\n",
    "    df_output = pd.DataFrame(x.reshape(-1, len(x)),columns = ['x1','x2','x3','x4'])\n",
    "    df_output['loss_estimate'] = loss_estimate\n",
    "    \n",
    "    return df_output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Maintain the BAxUS state\n",
    "\n",
    "\n",
    "BAxUS needs to maintain a state, which includes the length of the trust region, success and failure counters, success and failure tolerance, etc. In contrast to TuRBO, the failure tolerance depends on the target dimensionality.\n",
    "\n",
    "In this tutorial we store the state in a dataclass and update the state of TuRBO after each batch evaluation.\n",
    "\n",
    "Note: These settings assume that the domain has been scaled to [âˆ’1,1]ð‘‘\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "@dataclass\n",
    "class BaxusState:\n",
    "    dim: int\n",
    "    eval_budget: int\n",
    "    new_bins_on_split: int = 3\n",
    "    d_init: int = float(\"nan\")  # Note: post-initialized\n",
    "    target_dim: int = float(\"nan\")  # Note: post-initialized\n",
    "    n_splits: int = float(\"nan\")  # Note: post-initialized\n",
    "    length: float = 0.8\n",
    "    length_init: float = 0.8\n",
    "    length_min: float = 0.5**7\n",
    "    length_max: float = 1.6\n",
    "    failure_counter: int = 0\n",
    "    success_counter: int = 0\n",
    "    success_tolerance: int = 3\n",
    "    best_value: float = -float(\"inf\")\n",
    "    restart_triggered: bool = False\n",
    "\n",
    "    def __post_init__(self):\n",
    "        n_splits = round(math.log(self.dim, self.new_bins_on_split + 1))\n",
    "        self.d_init = 1 + np.argmin(\n",
    "            np.abs(\n",
    "                (1 + np.arange(self.new_bins_on_split))\n",
    "                * (1 + self.new_bins_on_split) ** n_splits\n",
    "                - self.dim\n",
    "            )\n",
    "        )\n",
    "        self.target_dim = self.d_init\n",
    "        self.n_splits = n_splits\n",
    "\n",
    "    @property\n",
    "    def split_budget(self) -> int:\n",
    "        return round(\n",
    "            -1\n",
    "            * (self.new_bins_on_split * self.eval_budget * self.target_dim)\n",
    "            / (self.d_init * (1 - (self.new_bins_on_split + 1) ** (self.n_splits + 1)))\n",
    "        )\n",
    "\n",
    "    @property\n",
    "    def failure_tolerance(self) -> int:\n",
    "        if self.target_dim == self.dim:\n",
    "            return self.target_dim\n",
    "        k = math.floor(math.log(self.length_min / self.length_init, 0.5))\n",
    "        split_budget = self.split_budget\n",
    "        return min(self.target_dim, max(1, math.floor(split_budget / k)))\n",
    "\n",
    "\n",
    "def update_state(state, Y_next):\n",
    "    if max(Y_next) > state.best_value + 1e-3 * math.fabs(state.best_value):\n",
    "        state.success_counter += 1\n",
    "        state.failure_counter = 0\n",
    "    else:\n",
    "        state.success_counter = 0\n",
    "        state.failure_counter += 1\n",
    "\n",
    "    if state.success_counter == state.success_tolerance:  # Expand trust region\n",
    "        state.length = min(2.0 * state.length, state.length_max)\n",
    "        state.success_counter = 0\n",
    "    elif state.failure_counter == state.failure_tolerance:  # Shrink trust region\n",
    "        state.length /= 2.0\n",
    "        state.failure_counter = 0\n",
    "\n",
    "    state.best_value = max(state.best_value, max(Y_next).item())\n",
    "    if state.length < state.length_min:\n",
    "        state.restart_triggered = True\n",
    "    return state"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Create a BAxUS embedding\n",
    "\n",
    "We now show how to create the BAxUS embedding. The essential idea is to assign input dimensions to target dimensions and to assign a sign +/- 1\n",
    " to each input dimension, similar to the HeSBO embedding. We create the embedding matrix that is used to project points from the target to the input space. The matrix is sparse, each column has precisely one non-zero entry that is either 1 or -1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.,  1.,  1.,  0.,  0., -1.,  0., -1.,  0.,  0.],\n",
       "        [ 0.,  0.,  0.,  1.,  0.,  0.,  1.,  0.,  0., -1.],\n",
       "        [ 1.,  0.,  0.,  0.,  1.,  0.,  0.,  0., -1.,  0.]],\n",
       "       dtype=torch.float64)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def embedding_matrix(input_dim: int, target_dim: int) -> torch.Tensor:\n",
    "    if (\n",
    "        target_dim >= input_dim\n",
    "    ):  # return identity matrix if target size greater than input size\n",
    "        return torch.eye(input_dim, device=device, dtype=dtype)\n",
    "\n",
    "    input_dims_perm = (\n",
    "        torch.randperm(input_dim, device=device) + 1\n",
    "    )  # add 1 to indices for padding column in matrix\n",
    "\n",
    "    bins = torch.tensor_split(\n",
    "        input_dims_perm, target_dim\n",
    "    )  # split dims into almost equally-sized bins\n",
    "    bins = torch.nn.utils.rnn.pad_sequence(\n",
    "        bins, batch_first=True\n",
    "    )  # zero pad bins, the index 0 will be cut off later\n",
    "\n",
    "    mtrx = torch.zeros(\n",
    "        (target_dim, input_dim + 1), dtype=dtype, device=device\n",
    "    )  # add one extra column for padding\n",
    "    mtrx = mtrx.scatter_(\n",
    "        1,\n",
    "        bins,\n",
    "        2 * torch.randint(2, (target_dim, input_dim), dtype=dtype, device=device) - 1,\n",
    "    )  # fill mask with random +/- 1 at indices\n",
    "\n",
    "    return mtrx[:, 1:]  # cut off index zero as this corresponds to zero padding\n",
    "\n",
    "\n",
    "embedding_matrix(10, 3)  # example for an embedding matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Function to increase the embedding\n",
    "\n",
    "Next, we write a helper function to increase the embedding and to bring observations to the increased target space.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def increase_embedding_and_observations(\n",
    "    S: torch.Tensor, X: torch.Tensor, n_new_bins: int\n",
    ") -> torch.Tensor:\n",
    "    assert X.size(1) == S.size(0), \"Observations don't lie in row space of S\"\n",
    "\n",
    "    S_update = S.clone()\n",
    "    X_update = X.clone()\n",
    "\n",
    "    for row_idx in range(len(S)):\n",
    "        row = S[row_idx]\n",
    "        idxs_non_zero = torch.nonzero(row)\n",
    "        idxs_non_zero = idxs_non_zero[torch.randperm(len(idxs_non_zero))].squeeze()\n",
    "\n",
    "        non_zero_elements = row[idxs_non_zero].squeeze()\n",
    "\n",
    "        n_row_bins = min(\n",
    "            n_new_bins, len(idxs_non_zero)\n",
    "        )  # number of new bins is always less or equal than the contributing input dims in the row minus one\n",
    "\n",
    "        new_bins = torch.tensor_split(idxs_non_zero, n_row_bins)[\n",
    "            1:\n",
    "        ]  # the dims in the first bin won't be moved\n",
    "        elements_to_move = torch.tensor_split(non_zero_elements, n_row_bins)[1:]\n",
    "\n",
    "        new_bins_padded = torch.nn.utils.rnn.pad_sequence(\n",
    "            new_bins, batch_first=True\n",
    "        )  # pad the tuples of bins with zeros to apply _scatter\n",
    "        els_to_move_padded = torch.nn.utils.rnn.pad_sequence(\n",
    "            elements_to_move, batch_first=True\n",
    "        )\n",
    "\n",
    "        S_stack = torch.zeros(\n",
    "            (n_row_bins - 1, len(row) + 1), device=device, dtype=dtype\n",
    "        )  # submatrix to stack on S_update\n",
    "\n",
    "        S_stack = S_stack.scatter_(\n",
    "            1, new_bins_padded + 1, els_to_move_padded\n",
    "        )  # fill with old values (add 1 to indices for padding column)\n",
    "\n",
    "        S_update[\n",
    "            row_idx, torch.hstack(new_bins)\n",
    "        ] = 0  # set values that were move to zero in current row\n",
    "\n",
    "        X_update = torch.hstack(\n",
    "            (X_update, X[:, row_idx].reshape(-1, 1).repeat(1, len(new_bins)))\n",
    "        )  # repeat observations for row at the end of X (column-wise)\n",
    "        S_update = torch.vstack(\n",
    "            (S_update, S_stack[:, 1:])\n",
    "        )  # stack onto S_update except for padding column\n",
    "\n",
    "    return S_update, X_update"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "S before increase\n",
      "tensor([[ 0.,  1.,  0., -1.,  0.,  1.,  0.,  0., -1., -1.],\n",
      "        [-1.,  0.,  1.,  0., -1.,  0.,  1., -1.,  0.,  0.]],\n",
      "       dtype=torch.float64)\n",
      "X before increase\n",
      "tensor([[ 8, 14],\n",
      "        [ 7, 27],\n",
      "        [81, 52],\n",
      "        [71, 53],\n",
      "        [66, 97],\n",
      "        [37, 29],\n",
      "        [68,  2]])\n",
      "S after increase\n",
      "tensor([[ 0.,  0.,  0., -1.,  0.,  0.,  0.,  0.,  0., -1.],\n",
      "        [-1.,  0.,  0.,  0.,  0.,  0.,  1.,  0.,  0.,  0.],\n",
      "        [ 0.,  0.,  0.,  0.,  0.,  1.,  0.,  0., -1.,  0.],\n",
      "        [ 0.,  1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.],\n",
      "        [ 0.,  0.,  0.,  0., -1.,  0.,  0., -1.,  0.,  0.],\n",
      "        [ 0.,  0.,  1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.]],\n",
      "       dtype=torch.float64)\n",
      "X after increase\n",
      "tensor([[ 8, 14,  8,  8, 14, 14],\n",
      "        [ 7, 27,  7,  7, 27, 27],\n",
      "        [81, 52, 81, 81, 52, 52],\n",
      "        [71, 53, 71, 71, 53, 53],\n",
      "        [66, 97, 66, 66, 97, 97],\n",
      "        [37, 29, 37, 37, 29, 29],\n",
      "        [68,  2, 68, 68,  2,  2]])\n"
     ]
    }
   ],
   "source": [
    "S = embedding_matrix(10, 2)\n",
    "X = torch.randint(100, (7, 2))\n",
    "print(f\"S before increase\\n{S}\")\n",
    "print(f\"X before increase\\n{X}\")\n",
    "\n",
    "S, X = increase_embedding_and_observations(S, X, 3)\n",
    "print(f\"S after increase\\n{S}\")\n",
    "print(f\"X after increase\\n{X}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Take a look at the state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BaxusState(dim=4, eval_budget=500, new_bins_on_split=3, d_init=1, target_dim=1, n_splits=1, length=0.8, length_init=0.8, length_min=0.0078125, length_max=1.6, failure_counter=0, success_counter=0, success_tolerance=3, best_value=-inf, restart_triggered=False)\n"
     ]
    }
   ],
   "source": [
    "state = BaxusState(dim=4, eval_budget=500)\n",
    "print(state)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generate initial points"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Generate new batch\n",
    "Given the current state and a probabilistic (GP) model built from observations X and Y, we generate a new batch of points.\n",
    "\n",
    "This method works on the domain [âˆ’1,+1]^d\n",
    ", so make sure to not pass in observations from the true domain. unnormalize is called before the true function is evaluated which will first map the points back to the original domain.\n",
    "\n",
    "We support either TS and qEI which can be specified via the acqf argument."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_candidate(\n",
    "    state,\n",
    "    model,  # GP model\n",
    "    X,  # Evaluated points on the domain [-1, 1]^d\n",
    "    Y,  # Function values\n",
    "    n_candidates=None,  # Number of candidates for Thompson sampling\n",
    "    num_restarts=10,\n",
    "    raw_samples=512,\n",
    "    acqf=\"ts\",  # \"ei\" or \"ts\"\n",
    "):\n",
    "    assert acqf in (\"ts\", \"ei\")\n",
    "    assert X.min() >= -1.0 and X.max() <= 1.0 and torch.all(torch.isfinite(Y))\n",
    "    if n_candidates is None:\n",
    "        n_candidates = min(5000, max(2000, 200 * X.shape[-1]))\n",
    "\n",
    "    # Scale the TR to be proportional to the lengthscales\n",
    "    x_center = X[Y.argmax(), :].clone()\n",
    "    weights = model.covar_module.base_kernel.lengthscale.detach().view(-1)\n",
    "    weights = weights / weights.mean()\n",
    "    weights = weights / torch.prod(weights.pow(1.0 / len(weights)))\n",
    "    tr_lb = torch.clamp(x_center - weights * state.length, -1.0, 1.0)\n",
    "    tr_ub = torch.clamp(x_center + weights * state.length, -1.0, 1.0)\n",
    "\n",
    "    if acqf == \"ts\":\n",
    "        dim = X.shape[-1]\n",
    "        sobol = SobolEngine(dim, scramble=True)\n",
    "        pert = sobol.draw(n_candidates).to(dtype=dtype, device=device)\n",
    "        pert = tr_lb + (tr_ub - tr_lb) * pert\n",
    "\n",
    "        # Create a perturbation mask\n",
    "        prob_perturb = min(20.0 / dim, 1.0)\n",
    "        mask = torch.rand(n_candidates, dim, dtype=dtype, device=device) <= prob_perturb\n",
    "        ind = torch.where(mask.sum(dim=1) == 0)[0]\n",
    "        mask[ind, torch.randint(0, dim, size=(len(ind),), device=device)] = 1\n",
    "\n",
    "        # Create candidate points from the perturbations and the mask\n",
    "        X_cand = x_center.expand(n_candidates, dim).clone()\n",
    "        X_cand[mask] = pert[mask]\n",
    "\n",
    "        # Sample on the candidate points\n",
    "        thompson_sampling = MaxPosteriorSampling(model=model, replacement=False)\n",
    "        with torch.no_grad():  # We don't need gradients when using TS\n",
    "            X_next = thompson_sampling(X_cand, num_samples=1)\n",
    "\n",
    "    elif acqf == \"ei\":\n",
    "        ei = ExpectedImprovement(model, train_Y.max(), maximize=True)\n",
    "        X_next, acq_value = optimize_acqf(\n",
    "            ei,\n",
    "            bounds=torch.stack([tr_lb, tr_ub]),\n",
    "            q=1,\n",
    "            num_restarts=num_restarts,\n",
    "            raw_samples=raw_samples,\n",
    "        )\n",
    "\n",
    "    return X_next"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Optimization loop\n",
    "\n",
    "This simple loop runs one instance of BAxUS with Thompson sampling until convergence.\n",
    "\n",
    "BAxUS works on a fixed evaluation budget and shrinks the trust region until the minimal trust region size is reached (state[\"restart_triggered\"] is set to True). Then, BAxUS increases the target space and carries over the observations to the updated space."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "bounds = torch.tensor([[400,400,400,400],[1000,1000,1000,1000]], device=device, dtype=dtype) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize(x,bounds):\n",
    "    lb = bounds[0]\n",
    "    ub = bounds[-1]\n",
    "\n",
    "    a = -(ub + lb)/(ub-lb)\n",
    "    b = 2/(ub - lb)\n",
    "\n",
    "    return a + b*x\n",
    "    \n",
    "\n",
    "def unnormalize(x,bounds):\n",
    "    lb = bounds[0]\n",
    "    ub = bounds[-1]\n",
    "\n",
    "    a = (ub + lb)/2\n",
    "    b = (ub - lb)/2\n",
    "\n",
    "    return a + b*x\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_initial_points(dim, n_pts, seed=0):\n",
    "    sobol = SobolEngine(dimension=dim, scramble=True, seed=seed)\n",
    "    X_init = (\n",
    "        2 * sobol.draw(n=n_pts).to(dtype=dtype, device=device) - 1\n",
    "    )  # points have to be in [-1, 1]^d\n",
    "    return X_init"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "dim = 4\n",
    "n_init = 20\n",
    "evaluation_budget = 100\n",
    "\n",
    "state = BaxusState(dim=dim, eval_budget=evaluation_budget - n_init)\n",
    "S = embedding_matrix(input_dim=state.dim, target_dim=state.d_init)\n",
    "\n",
    "X_baxus_target = get_initial_points(state.d_init, n_init)\n",
    "X_baxus_input = X_baxus_target @ S\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "printing /Users/rodrse/Documents/DemandCalibration/notebooks/od_calibration_sumo_files/quickstart/data/iter_quickstart.current_od.xml\n",
      "### Runing: iter\n",
      "Success.\n",
      "Step #57600.00 (7ms ~= 142.86*RT, ~105428.57UPS, vehicles TOT 2798 ACT 738 BUF 0)         \n",
      "printing /Users/rodrse/Documents/DemandCalibration/notebooks/od_calibration_sumo_files/quickstart/data/iter_quickstart.current_od.xml\n",
      "### Runing: iter\n",
      "Success.\n",
      "Step #57600.00 (8ms ~= 125.00*RT, ~92000.00UPS, vehicles TOT 2757 ACT 736 BUF 41)         \n",
      "printing /Users/rodrse/Documents/DemandCalibration/notebooks/od_calibration_sumo_files/quickstart/data/iter_quickstart.current_od.xml\n",
      "### Runing: iter\n",
      "Success.\n",
      "Step #57600.00 (6ms ~= 166.67*RT, ~151166.67UPS, vehicles TOT 2574 ACT 907 BUF 224)       \n",
      "printing /Users/rodrse/Documents/DemandCalibration/notebooks/od_calibration_sumo_files/quickstart/data/iter_quickstart.current_od.xml\n",
      "### Runing: iter\n",
      "Success.\n",
      "Step #57600.00 (5ms ~= 200.00*RT, ~105200.00UPS, vehicles TOT 2798 ACT 526 BUF 0)         \n",
      "printing /Users/rodrse/Documents/DemandCalibration/notebooks/od_calibration_sumo_files/quickstart/data/iter_quickstart.current_od.xml\n",
      "### Runing: iter\n",
      "Success.\n",
      "Step #57600.00 (6ms ~= 166.67*RT, ~110500.00UPS, vehicles TOT 2798 ACT 663 BUF 0)         \n",
      "printing /Users/rodrse/Documents/DemandCalibration/notebooks/od_calibration_sumo_files/quickstart/data/iter_quickstart.current_od.xml\n",
      "### Runing: iter\n",
      "Success.\n",
      "Step #57600.00 (7ms ~= 142.86*RT, ~132571.43UPS, vehicles TOT 2735 ACT 928 BUF 63)        \n",
      "printing /Users/rodrse/Documents/DemandCalibration/notebooks/od_calibration_sumo_files/quickstart/data/iter_quickstart.current_od.xml\n",
      "### Runing: iter\n",
      "Success.\n",
      "Step #57600.00 (8ms ~= 125.00*RT, ~111000.00UPS, vehicles TOT 2727 ACT 888 BUF 71)        \n",
      "printing /Users/rodrse/Documents/DemandCalibration/notebooks/od_calibration_sumo_files/quickstart/data/iter_quickstart.current_od.xml\n",
      "### Runing: iter\n",
      "Success.\n",
      "Step #57600.00 (6ms ~= 166.67*RT, ~111000.00UPS, vehicles TOT 2798 ACT 666 BUF 0)         \n",
      "printing /Users/rodrse/Documents/DemandCalibration/notebooks/od_calibration_sumo_files/quickstart/data/iter_quickstart.current_od.xml\n",
      "### Runing: iter\n",
      "Success.\n",
      "Step #57600.00 (5ms ~= 200.00*RT, ~129200.00UPS, vehicles TOT 2798 ACT 646 BUF 0)         \n",
      "printing /Users/rodrse/Documents/DemandCalibration/notebooks/od_calibration_sumo_files/quickstart/data/iter_quickstart.current_od.xml\n",
      "### Runing: iter\n",
      "Success.\n",
      "Step #57600.00 (8ms ~= 125.00*RT, ~111125.00UPS, vehicles TOT 2788 ACT 889 BUF 10)        \n",
      "printing /Users/rodrse/Documents/DemandCalibration/notebooks/od_calibration_sumo_files/quickstart/data/iter_quickstart.current_od.xml\n",
      "### Runing: iter\n",
      "Success.\n",
      "Step #57600.00 (26ms ~= 38.46*RT, ~34230.77UPS, vehicles TOT 2688 ACT 890 BUF 110)        \n",
      "printing /Users/rodrse/Documents/DemandCalibration/notebooks/od_calibration_sumo_files/quickstart/data/iter_quickstart.current_od.xml\n",
      "### Runing: iter\n",
      "Success.\n",
      "Step #57600.00 (5ms ~= 200.00*RT, ~118800.00UPS, vehicles TOT 2798 ACT 594 BUF 0)         \n",
      "printing /Users/rodrse/Documents/DemandCalibration/notebooks/od_calibration_sumo_files/quickstart/data/iter_quickstart.current_od.xml\n",
      "### Runing: iter\n",
      "Success.\n",
      "Step #57600.00 (4ms ~= 250.00*RT, ~143000.00UPS, vehicles TOT 2798 ACT 572 BUF 0)         \n",
      "printing /Users/rodrse/Documents/DemandCalibration/notebooks/od_calibration_sumo_files/quickstart/data/iter_quickstart.current_od.xml\n",
      "### Runing: iter\n",
      "Success.\n",
      "Step #57600.00 (6ms ~= 166.67*RT, ~149500.00UPS, vehicles TOT 2736 ACT 897 BUF 62)        \n",
      "printing /Users/rodrse/Documents/DemandCalibration/notebooks/od_calibration_sumo_files/quickstart/data/iter_quickstart.current_od.xml\n",
      "### Runing: iter\n",
      "Success.\n",
      "Step #57600.00 (5ms ~= 200.00*RT, ~164800.00UPS, vehicles TOT 2798 ACT 824 BUF 0)         \n",
      "printing /Users/rodrse/Documents/DemandCalibration/notebooks/od_calibration_sumo_files/quickstart/data/iter_quickstart.current_od.xml\n",
      "### Runing: iter\n",
      "Success.\n",
      "Step #57600.00 (10ms ~= 100.00*RT, ~68200.00UPS, vehicles TOT 2798 ACT 682 BUF 0)         \n",
      "printing /Users/rodrse/Documents/DemandCalibration/notebooks/od_calibration_sumo_files/quickstart/data/iter_quickstart.current_od.xml\n",
      "### Runing: iter\n",
      "Success.\n",
      "Step #57600.00 (6ms ~= 166.67*RT, ~115166.67UPS, vehicles TOT 2798 ACT 691 BUF 0)         \n",
      "printing /Users/rodrse/Documents/DemandCalibration/notebooks/od_calibration_sumo_files/quickstart/data/iter_quickstart.current_od.xml\n",
      "### Runing: iter\n",
      "Success.\n",
      "Step #57600.00 (10ms ~= 100.00*RT, ~84100.00UPS, vehicles TOT 2798 ACT 841 BUF 0)         \n",
      "printing /Users/rodrse/Documents/DemandCalibration/notebooks/od_calibration_sumo_files/quickstart/data/iter_quickstart.current_od.xml\n",
      "### Runing: iter\n",
      "Success.\n",
      "Step #57600.00 (7ms ~= 142.86*RT, ~120857.14UPS, vehicles TOT 2624 ACT 846 BUF 174)       \n",
      "printing /Users/rodrse/Documents/DemandCalibration/notebooks/od_calibration_sumo_files/quickstart/data/iter_quickstart.current_od.xml\n",
      "### Runing: iter\n",
      "Success.\n",
      "Step #57600.00 (7ms ~= 142.86*RT, ~83714.29UPS, vehicles TOT 2798 ACT 586 BUF 0)          \n"
     ]
    }
   ],
   "source": [
    "\n",
    "sumo_output = [\n",
    "    objective(x) for x in unnormalize(X_baxus_input,bounds).cpu().detach().numpy()\n",
    "]\n",
    "\n",
    "df_0 = pd.concat(sumo_output)\n",
    "df_0['iter'] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "SMOKE_TEST = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.2459],\n",
       "        [ 0.0395],\n",
       "        [-1.9863],\n",
       "        [ 0.5816],\n",
       "        [ 1.4571],\n",
       "        [-1.0912],\n",
       "        [-0.8915],\n",
       "        [ 1.0500],\n",
       "        [ 0.9052],\n",
       "        [-0.5030],\n",
       "        [-1.1829],\n",
       "        [ 1.1912],\n",
       "        [ 0.7328],\n",
       "        [-1.0556],\n",
       "        [-0.1357],\n",
       "        [ 0.6785],\n",
       "        [ 0.5954],\n",
       "        [-0.1363],\n",
       "        [-1.4571],\n",
       "        [ 0.9624]], dtype=torch.float64)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### Run loop\n",
    "NITER = 100\n",
    "output = [df_0]\n",
    "best_value = []\n",
    "S_matrix = [S]\n",
    "\n",
    "\n",
    "NUM_RESTARTS = 10 if not SMOKE_TEST else 2\n",
    "RAW_SAMPLES = 512 if not SMOKE_TEST else 4\n",
    "N_CANDIDATES = min(5000, max(2000, 200 * dim)) if not SMOKE_TEST else 4\n",
    "max_cholesky_size = float(\"inf\")  # Always use Cholesky\n",
    "\n",
    "Y_baxus = -1.0 * torch.from_numpy(df_0[[\"loss_estimate\"]].values)\n",
    "(Y_baxus - Y_baxus.mean()) / Y_baxus.std()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "####### 1 ########\n",
      "##### best_value=-0.006946893070289898 #####\n",
      "printing /Users/rodrse/Documents/DemandCalibration/notebooks/od_calibration_sumo_files/quickstart/data/iter_quickstart.current_od.xml\n",
      "### Runing: iter\n",
      "Success.\n",
      "Step #57600.00 (10ms ~= 100.00*RT, ~67700.00UPS, vehicles TOT 2798 ACT 677 BUF 0)         \n",
      "iteration 21, d=1)  Best value: -0.0206, TR length: 0.4\n",
      "####### 2 ########\n",
      "##### best_value=-0.006946893070289898 #####\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/rodrse/anaconda3/envs/BoTorch/lib/python3.9/site-packages/linear_operator/utils/cholesky.py:40: NumericalWarning: A not p.d., added jitter of 1.0e-08 to the diagonal\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "printing /Users/rodrse/Documents/DemandCalibration/notebooks/od_calibration_sumo_files/quickstart/data/iter_quickstart.current_od.xml\n",
      "### Runing: iter\n",
      "Success.\n",
      "Step #57600.00 (8ms ~= 125.00*RT, ~81500.00UPS, vehicles TOT 2798 ACT 652 BUF 0)          \n",
      "iteration 22, d=1)  Best value: -0.0104, TR length: 0.4\n",
      "####### 3 ########\n",
      "##### best_value=-0.006946893070289898 #####\n",
      "printing /Users/rodrse/Documents/DemandCalibration/notebooks/od_calibration_sumo_files/quickstart/data/iter_quickstart.current_od.xml\n",
      "### Runing: iter\n",
      "Success.\n",
      "Step #57600.00 (5ms ~= 200.00*RT, ~134200.00UPS, vehicles TOT 2798 ACT 671 BUF 0)         \n",
      "iteration 23, d=1)  Best value: -0.0104, TR length: 0.2\n",
      "####### 4 ########\n",
      "##### best_value=-0.006946893070289898 #####\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/rodrse/anaconda3/envs/BoTorch/lib/python3.9/site-packages/linear_operator/utils/cholesky.py:40: NumericalWarning: A not p.d., added jitter of 1.0e-08 to the diagonal\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "printing /Users/rodrse/Documents/DemandCalibration/notebooks/od_calibration_sumo_files/quickstart/data/iter_quickstart.current_od.xml\n",
      "### Runing: iter\n",
      "Success.\n",
      "Step #57600.00 (4ms ~= 250.00*RT, ~159000.00UPS, vehicles TOT 2798 ACT 636 BUF 0)         \n",
      "iteration 24, d=1)  Best value: -0.00655, TR length: 0.2\n",
      "####### 5 ########\n",
      "##### best_value=-0.006549593597573095 #####\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/rodrse/anaconda3/envs/BoTorch/lib/python3.9/site-packages/linear_operator/utils/cholesky.py:40: NumericalWarning: A not p.d., added jitter of 1.0e-08 to the diagonal\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "printing /Users/rodrse/Documents/DemandCalibration/notebooks/od_calibration_sumo_files/quickstart/data/iter_quickstart.current_od.xml\n",
      "### Runing: iter\n",
      "Success.\n",
      "Step #57600.00 (5ms ~= 200.00*RT, ~137000.00UPS, vehicles TOT 2798 ACT 685 BUF 0)         \n",
      "iteration 25, d=1)  Best value: -0.00655, TR length: 0.1\n",
      "####### 6 ########\n",
      "##### best_value=-0.006549593597573095 #####\n",
      "printing /Users/rodrse/Documents/DemandCalibration/notebooks/od_calibration_sumo_files/quickstart/data/iter_quickstart.current_od.xml\n",
      "### Runing: iter\n",
      "Success.\n",
      "Step #57600.00 (5ms ~= 200.00*RT, ~138200.00UPS, vehicles TOT 2798 ACT 691 BUF 0)         \n",
      "iteration 26, d=1)  Best value: -0.00655, TR length: 0.05\n",
      "####### 7 ########\n",
      "##### best_value=-0.006549593597573095 #####\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/rodrse/anaconda3/envs/BoTorch/lib/python3.9/site-packages/linear_operator/utils/cholesky.py:40: NumericalWarning: A not p.d., added jitter of 1.0e-08 to the diagonal\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "printing /Users/rodrse/Documents/DemandCalibration/notebooks/od_calibration_sumo_files/quickstart/data/iter_quickstart.current_od.xml\n",
      "### Runing: iter\n",
      "Success.\n",
      "Step #57600.00 (5ms ~= 200.00*RT, ~135800.00UPS, vehicles TOT 2798 ACT 679 BUF 0)         \n",
      "iteration 27, d=1)  Best value: -0.00655, TR length: 0.025\n",
      "####### 8 ########\n",
      "##### best_value=-0.006549593597573095 #####\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/rodrse/anaconda3/envs/BoTorch/lib/python3.9/site-packages/linear_operator/utils/cholesky.py:40: NumericalWarning: A not p.d., added jitter of 1.0e-08 to the diagonal\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "printing /Users/rodrse/Documents/DemandCalibration/notebooks/od_calibration_sumo_files/quickstart/data/iter_quickstart.current_od.xml\n",
      "### Runing: iter\n",
      "Success.\n",
      "Step #57600.00 (12ms ~= 83.33*RT, ~54333.33UPS, vehicles TOT 2798 ACT 652 BUF 0)          \n",
      "iteration 28, d=1)  Best value: -0.00655, TR length: 0.0125\n",
      "####### 9 ########\n",
      "##### best_value=-0.006549593597573095 #####\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/rodrse/anaconda3/envs/BoTorch/lib/python3.9/site-packages/linear_operator/utils/cholesky.py:40: NumericalWarning: A not p.d., added jitter of 1.0e-08 to the diagonal\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "printing /Users/rodrse/Documents/DemandCalibration/notebooks/od_calibration_sumo_files/quickstart/data/iter_quickstart.current_od.xml\n",
      "### Runing: iter\n",
      "Success.\n",
      "Step #57600.00 (5ms ~= 200.00*RT, ~127200.00UPS, vehicles TOT 2798 ACT 636 BUF 0)         \n",
      "iteration 29, d=1)  Best value: -0.00655, TR length: 0.00625\n",
      "increasing target space\n",
      "new dimensionality: 3\n",
      "####### 10 ########\n",
      "##### best_value=-0.006549593597573095 #####\n",
      "printing /Users/rodrse/Documents/DemandCalibration/notebooks/od_calibration_sumo_files/quickstart/data/iter_quickstart.current_od.xml\n",
      "### Runing: iter\n",
      "Success.\n",
      "Step #57600.00 (7ms ~= 142.86*RT, ~112857.14UPS, vehicles TOT 2969 ACT 790 BUF 0)         \n",
      "iteration 30, d=3)  Best value: -0.00655, TR length: 0.8\n",
      "####### 11 ########\n",
      "##### best_value=-0.006549593597573095 #####\n",
      "printing /Users/rodrse/Documents/DemandCalibration/notebooks/od_calibration_sumo_files/quickstart/data/iter_quickstart.current_od.xml\n",
      "### Runing: iter\n",
      "Success.\n",
      "Step #57600.00 (8ms ~= 125.00*RT, ~106500.00UPS, vehicles TOT 3194 ACT 852 BUF 578)       \n",
      "iteration 31, d=3)  Best value: -0.00655, TR length: 0.8\n",
      "####### 12 ########\n",
      "##### best_value=-0.006549593597573095 #####\n",
      "printing /Users/rodrse/Documents/DemandCalibration/notebooks/od_calibration_sumo_files/quickstart/data/iter_quickstart.current_od.xml\n",
      "### Runing: iter\n",
      "Success.\n",
      "Step #57600.00 (5ms ~= 200.00*RT, ~129800.00UPS, vehicles TOT 2482 ACT 649 BUF 0)         \n",
      "iteration 32, d=3)  Best value: -0.00655, TR length: 0.4\n",
      "####### 13 ########\n",
      "##### best_value=-0.006549593597573095 #####\n",
      "printing /Users/rodrse/Documents/DemandCalibration/notebooks/od_calibration_sumo_files/quickstart/data/iter_quickstart.current_od.xml\n",
      "### Runing: iter\n",
      "Success.\n",
      "Step #57600.00 (4ms ~= 250.00*RT, ~133250.00UPS, vehicles TOT 2267 ACT 533 BUF 0)         \n",
      "iteration 33, d=3)  Best value: -0.00655, TR length: 0.4\n",
      "####### 14 ########\n",
      "##### best_value=-0.006549593597573095 #####\n",
      "printing /Users/rodrse/Documents/DemandCalibration/notebooks/od_calibration_sumo_files/quickstart/data/iter_quickstart.current_od.xml\n",
      "### Runing: iter\n",
      "Success.\n",
      "Step #57600.00 (7ms ~= 142.86*RT, ~116714.29UPS, vehicles TOT 3039 ACT 817 BUF 0)         \n",
      "iteration 34, d=3)  Best value: -0.00655, TR length: 0.4\n",
      "####### 15 ########\n",
      "##### best_value=-0.006549593597573095 #####\n",
      "printing /Users/rodrse/Documents/DemandCalibration/notebooks/od_calibration_sumo_files/quickstart/data/iter_quickstart.current_od.xml\n",
      "### Runing: iter\n",
      "Success.\n",
      "Step #57600.00 (4ms ~= 250.00*RT, ~130250.00UPS, vehicles TOT 2703 ACT 521 BUF 0)         \n",
      "iteration 35, d=3)  Best value: -0.00655, TR length: 0.2\n",
      "####### 16 ########\n",
      "##### best_value=-0.006549593597573095 #####\n",
      "printing /Users/rodrse/Documents/DemandCalibration/notebooks/od_calibration_sumo_files/quickstart/data/iter_quickstart.current_od.xml\n",
      "### Runing: iter\n",
      "Success.\n",
      "Step #57600.00 (5ms ~= 200.00*RT, ~128800.00UPS, vehicles TOT 2804 ACT 644 BUF 0)         \n",
      "iteration 36, d=3)  Best value: -0.00655, TR length: 0.2\n",
      "####### 17 ########\n",
      "##### best_value=-0.006549593597573095 #####\n",
      "printing /Users/rodrse/Documents/DemandCalibration/notebooks/od_calibration_sumo_files/quickstart/data/iter_quickstart.current_od.xml\n",
      "### Runing: iter\n",
      "Success.\n",
      "Step #57600.00 (3ms ~= 333.33*RT, ~140666.67UPS, vehicles TOT 2477 ACT 422 BUF 0)         \n",
      "iteration 37, d=3)  Best value: -0.00655, TR length: 0.2\n",
      "####### 18 ########\n",
      "##### best_value=-0.006549593597573095 #####\n",
      "printing /Users/rodrse/Documents/DemandCalibration/notebooks/od_calibration_sumo_files/quickstart/data/iter_quickstart.current_od.xml\n",
      "### Runing: iter\n",
      "Success.\n",
      "Step #57600.00 (8ms ~= 125.00*RT, ~90500.00UPS, vehicles TOT 2701 ACT 724 BUF 0)          \n",
      "iteration 38, d=3)  Best value: -0.00655, TR length: 0.1\n",
      "####### 19 ########\n",
      "##### best_value=-0.006549593597573095 #####\n",
      "printing /Users/rodrse/Documents/DemandCalibration/notebooks/od_calibration_sumo_files/quickstart/data/iter_quickstart.current_od.xml\n",
      "### Runing: iter\n",
      "Success.\n",
      "Step #57600.00 (5ms ~= 200.00*RT, ~111000.00UPS, vehicles TOT 2560 ACT 555 BUF 0)         \n",
      "iteration 39, d=3)  Best value: -0.00655, TR length: 0.1\n",
      "####### 20 ########\n",
      "##### best_value=-0.006549593597573095 #####\n",
      "printing /Users/rodrse/Documents/DemandCalibration/notebooks/od_calibration_sumo_files/quickstart/data/iter_quickstart.current_od.xml\n",
      "### Runing: iter\n",
      "Success.\n",
      "Step #57600.00 (7ms ~= 142.86*RT, ~98142.86UPS, vehicles TOT 2885 ACT 687 BUF 0)          \n",
      "iteration 40, d=3)  Best value: -0.00655, TR length: 0.1\n",
      "####### 21 ########\n",
      "##### best_value=-0.006549593597573095 #####\n",
      "printing /Users/rodrse/Documents/DemandCalibration/notebooks/od_calibration_sumo_files/quickstart/data/iter_quickstart.current_od.xml\n",
      "### Runing: iter\n",
      "Success.\n",
      "Step #57600.00 (8ms ~= 125.00*RT, ~96000.00UPS, vehicles TOT 2994 ACT 768 BUF 0)          \n",
      "iteration 41, d=3)  Best value: -0.00655, TR length: 0.05\n",
      "####### 22 ########\n",
      "##### best_value=-0.006549593597573095 #####\n",
      "printing /Users/rodrse/Documents/DemandCalibration/notebooks/od_calibration_sumo_files/quickstart/data/iter_quickstart.current_od.xml\n",
      "### Runing: iter\n",
      "Success.\n",
      "Step #57600.00 (6ms ~= 166.67*RT, ~117333.33UPS, vehicles TOT 2867 ACT 704 BUF 0)         \n",
      "iteration 42, d=3)  Best value: -0.00655, TR length: 0.05\n",
      "####### 23 ########\n",
      "##### best_value=-0.006549593597573095 #####\n",
      "printing /Users/rodrse/Documents/DemandCalibration/notebooks/od_calibration_sumo_files/quickstart/data/iter_quickstart.current_od.xml\n",
      "### Runing: iter\n",
      "Success.\n",
      "Step #57600.00 (5ms ~= 200.00*RT, ~149600.00UPS, vehicles TOT 2911 ACT 748 BUF 0)         \n",
      "iteration 43, d=3)  Best value: -0.00655, TR length: 0.05\n",
      "####### 24 ########\n",
      "##### best_value=-0.006549593597573095 #####\n",
      "printing /Users/rodrse/Documents/DemandCalibration/notebooks/od_calibration_sumo_files/quickstart/data/iter_quickstart.current_od.xml\n",
      "### Runing: iter\n",
      "Success.\n",
      "Step #57600.00 (5ms ~= 200.00*RT, ~127000.00UPS, vehicles TOT 2760 ACT 635 BUF 0)         \n",
      "iteration 44, d=3)  Best value: -0.00655, TR length: 0.025\n",
      "####### 25 ########\n",
      "##### best_value=-0.006549593597573095 #####\n",
      "printing /Users/rodrse/Documents/DemandCalibration/notebooks/od_calibration_sumo_files/quickstart/data/iter_quickstart.current_od.xml\n",
      "### Runing: iter\n",
      "Success.\n",
      "Step #57600.00 (4ms ~= 250.00*RT, ~143250.00UPS, vehicles TOT 2728 ACT 573 BUF 0)         \n",
      "iteration 45, d=3)  Best value: -0.00203, TR length: 0.025\n",
      "####### 26 ########\n",
      "##### best_value=-0.0020309427588553947 #####\n",
      "printing /Users/rodrse/Documents/DemandCalibration/notebooks/od_calibration_sumo_files/quickstart/data/iter_quickstart.current_od.xml\n",
      "### Runing: iter\n",
      "Success.\n",
      "Step #57600.00 (5ms ~= 200.00*RT, ~125200.00UPS, vehicles TOT 2717 ACT 626 BUF 0)         \n",
      "iteration 46, d=3)  Best value: -0.00203, TR length: 0.025\n",
      "####### 27 ########\n",
      "##### best_value=-0.0020309427588553947 #####\n",
      "printing /Users/rodrse/Documents/DemandCalibration/notebooks/od_calibration_sumo_files/quickstart/data/iter_quickstart.current_od.xml\n",
      "### Runing: iter\n",
      "Success.\n",
      "Step #57600.00 (4ms ~= 250.00*RT, ~154000.00UPS, vehicles TOT 2729 ACT 616 BUF 0)         \n",
      "iteration 47, d=3)  Best value: -0.00203, TR length: 0.025\n",
      "####### 28 ########\n",
      "##### best_value=-0.0020309427588553947 #####\n",
      "printing /Users/rodrse/Documents/DemandCalibration/notebooks/od_calibration_sumo_files/quickstart/data/iter_quickstart.current_od.xml\n",
      "### Runing: iter\n",
      "Success.\n",
      "Step #57600.00 (6ms ~= 166.67*RT, ~104500.00UPS, vehicles TOT 2674 ACT 627 BUF 0)         \n",
      "iteration 48, d=3)  Best value: -0.00203, TR length: 0.0125\n",
      "####### 29 ########\n",
      "##### best_value=-0.0020309427588553947 #####\n",
      "printing /Users/rodrse/Documents/DemandCalibration/notebooks/od_calibration_sumo_files/quickstart/data/iter_quickstart.current_od.xml\n",
      "### Runing: iter\n",
      "Success.\n",
      "Step #57600.00 (5ms ~= 200.00*RT, ~122800.00UPS, vehicles TOT 2675 ACT 614 BUF 0)         \n",
      "iteration 49, d=3)  Best value: -0.00203, TR length: 0.0125\n",
      "####### 30 ########\n",
      "##### best_value=-0.0020309427588553947 #####\n",
      "printing /Users/rodrse/Documents/DemandCalibration/notebooks/od_calibration_sumo_files/quickstart/data/iter_quickstart.current_od.xml\n",
      "### Runing: iter\n",
      "Success.\n",
      "Step #57600.00 (4ms ~= 250.00*RT, ~160750.00UPS, vehicles TOT 2719 ACT 643 BUF 0)         \n",
      "iteration 50, d=3)  Best value: -0.00203, TR length: 0.0125\n",
      "####### 31 ########\n",
      "##### best_value=-0.0020309427588553947 #####\n",
      "printing /Users/rodrse/Documents/DemandCalibration/notebooks/od_calibration_sumo_files/quickstart/data/iter_quickstart.current_od.xml\n",
      "### Runing: iter\n",
      "Success.\n",
      "Step #57600.00 (6ms ~= 166.67*RT, ~120666.67UPS, vehicles TOT 2872 ACT 724 BUF 0)         \n",
      "iteration 51, d=3)  Best value: -0.00203, TR length: 0.00625\n",
      "increasing target space\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "len() of a 0-d tensor",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[22], line 95\u001b[0m\n\u001b[1;32m     93\u001b[0m state\u001b[39m.\u001b[39mrestart_triggered \u001b[39m=\u001b[39m \u001b[39mFalse\u001b[39;00m\n\u001b[1;32m     94\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39m\"\u001b[39m\u001b[39mincreasing target space\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m---> 95\u001b[0m S, X_baxus_target \u001b[39m=\u001b[39m increase_embedding_and_observations(\n\u001b[1;32m     96\u001b[0m     S, X_baxus_target, state\u001b[39m.\u001b[39;49mnew_bins_on_split\n\u001b[1;32m     97\u001b[0m )\n\u001b[1;32m     98\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mnew dimensionality: \u001b[39m\u001b[39m{\u001b[39;00m\u001b[39mlen\u001b[39m(S)\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m)\n\u001b[1;32m     99\u001b[0m state\u001b[39m.\u001b[39mtarget_dim \u001b[39m=\u001b[39m \u001b[39mlen\u001b[39m(S)\n",
      "Cell \u001b[0;32mIn[7], line 17\u001b[0m, in \u001b[0;36mincrease_embedding_and_observations\u001b[0;34m(S, X, n_new_bins)\u001b[0m\n\u001b[1;32m     12\u001b[0m idxs_non_zero \u001b[39m=\u001b[39m idxs_non_zero[torch\u001b[39m.\u001b[39mrandperm(\u001b[39mlen\u001b[39m(idxs_non_zero))]\u001b[39m.\u001b[39msqueeze()\n\u001b[1;32m     14\u001b[0m non_zero_elements \u001b[39m=\u001b[39m row[idxs_non_zero]\u001b[39m.\u001b[39msqueeze()\n\u001b[1;32m     16\u001b[0m n_row_bins \u001b[39m=\u001b[39m \u001b[39mmin\u001b[39m(\n\u001b[0;32m---> 17\u001b[0m     n_new_bins, \u001b[39mlen\u001b[39;49m(idxs_non_zero)\n\u001b[1;32m     18\u001b[0m )  \u001b[39m# number of new bins is always less or equal than the contributing input dims in the row minus one\u001b[39;00m\n\u001b[1;32m     20\u001b[0m new_bins \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39mtensor_split(idxs_non_zero, n_row_bins)[\n\u001b[1;32m     21\u001b[0m     \u001b[39m1\u001b[39m:\n\u001b[1;32m     22\u001b[0m ]  \u001b[39m# the dims in the first bin won't be moved\u001b[39;00m\n\u001b[1;32m     23\u001b[0m elements_to_move \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39mtensor_split(non_zero_elements, n_row_bins)[\u001b[39m1\u001b[39m:]\n",
      "File \u001b[0;32m~/anaconda3/envs/BoTorch/lib/python3.9/site-packages/torch/_tensor.py:894\u001b[0m, in \u001b[0;36mTensor.__len__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    892\u001b[0m     \u001b[39mreturn\u001b[39;00m handle_torch_function(Tensor\u001b[39m.\u001b[39m\u001b[39m__len__\u001b[39m, (\u001b[39mself\u001b[39m,), \u001b[39mself\u001b[39m)\n\u001b[1;32m    893\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdim() \u001b[39m==\u001b[39m \u001b[39m0\u001b[39m:\n\u001b[0;32m--> 894\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mTypeError\u001b[39;00m(\u001b[39m\"\u001b[39m\u001b[39mlen() of a 0-d tensor\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m    895\u001b[0m \u001b[39mif\u001b[39;00m torch\u001b[39m.\u001b[39m_C\u001b[39m.\u001b[39m_get_tracing_state():\n\u001b[1;32m    896\u001b[0m     warnings\u001b[39m.\u001b[39mwarn(\n\u001b[1;32m    897\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mUsing len to get tensor shape might cause the trace to be incorrect. \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    898\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mRecommended usage would be tensor.shape[0]. \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    902\u001b[0m         stacklevel\u001b[39m=\u001b[39m\u001b[39m2\u001b[39m,\n\u001b[1;32m    903\u001b[0m     )\n",
      "\u001b[0;31mTypeError\u001b[0m: len() of a 0-d tensor"
     ]
    }
   ],
   "source": [
    "\n",
    "# Disable input scaling checks as we normalize to [-1, 1]\n",
    "with botorch.settings.validate_input_scaling(False):\n",
    "\n",
    "    for i in range(evaluation_budget - n_init):  # Run until evaluation budget depleted\n",
    "    #for i in range(2):  # Run until evaluation budget depleted\n",
    "\n",
    "        print(f\"####### {i+1} ########\")\n",
    "\n",
    "        # best value so far\n",
    "        best_y = Y_baxus.max()\n",
    "        best_value.append(best_y)\n",
    "\n",
    "        print(f\"##### best_value={best_y} #####\")\n",
    "\n",
    "        # Fit a GP model\n",
    "        train_Y = (Y_baxus - Y_baxus.mean()) / Y_baxus.std()\n",
    "        likelihood = GaussianLikelihood(noise_constraint=Interval(1e-8, 1e-3))\n",
    "        covar_module = (\n",
    "            ScaleKernel(  # Use the same lengthscale prior as in the TuRBO paper\n",
    "                MaternKernel(\n",
    "                    nu=2.5,\n",
    "                    ard_num_dims=state.target_dim,\n",
    "                    lengthscale_constraint=Interval(0.005, 10),\n",
    "                ),\n",
    "                outputscale_constraint=Interval(0.05, 10),\n",
    "            )\n",
    "        )\n",
    "        model = SingleTaskGP(\n",
    "            X_baxus_target, train_Y, covar_module=covar_module, likelihood=likelihood\n",
    "        )\n",
    "        mll = ExactMarginalLogLikelihood(model.likelihood, model)\n",
    "\n",
    "        # Do the fitting and acquisition function optimization inside the Cholesky context\n",
    "        with gpytorch.settings.max_cholesky_size(max_cholesky_size):\n",
    "            # Fit the model\n",
    "            try:\n",
    "                fit_gpytorch_mll(mll)\n",
    "            except ModelFittingError:\n",
    "                # Right after increasing the target dimensionality, the covariance matrix becomes indefinite\n",
    "                # In this case, the Cholesky decomposition might fail due to numerical instabilities\n",
    "                # In this case, we revert to Adam-based optimization\n",
    "                optimizer = torch.optim.Adam([{\"params\": model.parameters()}], lr=0.1)\n",
    "\n",
    "                for _ in range(100):\n",
    "                    optimizer.zero_grad()\n",
    "                    output = model(X_baxus_target)\n",
    "                    loss = -mll(output, train_Y.flatten())\n",
    "                    loss.backward()\n",
    "                    optimizer.step()\n",
    "\n",
    "            # Create a batch\n",
    "            X_next_target = create_candidate(\n",
    "                state=state,\n",
    "                model=model,\n",
    "                X=X_baxus_target,\n",
    "                Y=train_Y,\n",
    "                n_candidates=N_CANDIDATES,\n",
    "                num_restarts=NUM_RESTARTS,\n",
    "                raw_samples=RAW_SAMPLES,\n",
    "                acqf=\"ts\",\n",
    "            )\n",
    "\n",
    "        X_next_input = X_next_target @ S\n",
    "\n",
    "        # Query simulator\n",
    "        sumo_output_next = [\n",
    "            objective(x) for x in unnormalize(X_next_input,bounds).cpu().detach().numpy()\n",
    "        ]\n",
    "\n",
    "        df_i = pd.concat(sumo_output_next)\n",
    "        df_i['iter'] = i+1\n",
    "\n",
    "        Y_next = -1.0 * torch.from_numpy(df_i[[\"loss_estimate\"]].values)\n",
    "\n",
    "        # Update state\n",
    "        state = update_state(state=state, Y_next=Y_next)\n",
    "\n",
    "        # Append data\n",
    "        X_baxus_input = torch.cat((X_baxus_input, X_next_input), dim=0)\n",
    "        X_baxus_target = torch.cat((X_baxus_target, X_next_target), dim=0)\n",
    "        Y_baxus = torch.cat((Y_baxus, Y_next), dim=0)\n",
    "        S_matrix.append(S)\n",
    "\n",
    "        # Append simulator data\n",
    "        output.append(df_i)\n",
    "\n",
    "        # Print current status\n",
    "        print(\n",
    "            f\"iteration {len(X_baxus_input)}, d={len(X_baxus_target.T)})  Best value: {state.best_value:.3}, TR length: {state.length:.3}\"\n",
    "        )\n",
    "\n",
    "        if state.restart_triggered:\n",
    "            state.restart_triggered = False\n",
    "            print(\"increasing target space\")\n",
    "            S, X_baxus_target = increase_embedding_and_observations(\n",
    "                S, X_baxus_target, state.new_bins_on_split\n",
    "            )\n",
    "            print(f\"new dimensionality: {len(S)}\")\n",
    "            state.target_dim = len(S)\n",
    "            state.length = state.length_init\n",
    "            state.failure_counter = 0\n",
    "            state.success_counter = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 1., -1., -1.,  1.]], dtype=torch.float64)"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "S_matrix[3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 1.,  0.,  0.,  1.],\n",
       "        [ 0., -1.,  0.,  0.],\n",
       "        [ 0.,  0., -1.,  0.]], dtype=torch.float64)"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "S_matrix[-2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-0.0498, -0.0498, -0.0498],\n",
       "        [ 0.1202,  0.1202,  0.1202],\n",
       "        [ 0.9756,  0.9756,  0.9756],\n",
       "        [-0.9210, -0.9210, -0.9210],\n",
       "        [-0.5082, -0.5082, -0.5082],\n",
       "        [ 0.5642,  0.5642,  0.5642],\n",
       "        [ 0.4652,  0.4652,  0.4652],\n",
       "        [-0.3962, -0.3962, -0.3962],\n",
       "        [-0.3402, -0.3402, -0.3402],\n",
       "        [ 0.2712,  0.2712,  0.2712],\n",
       "        [ 0.6332,  0.6332,  0.6332],\n",
       "        [-0.6892, -0.6892, -0.6892],\n",
       "        [-0.8506, -0.8506, -0.8506],\n",
       "        [ 0.7960,  0.7960,  0.7960],\n",
       "        [ 0.1748,  0.1748,  0.1748],\n",
       "        [-0.2453, -0.2453, -0.2453],\n",
       "        [-0.1428, -0.1428, -0.1428],\n",
       "        [ 0.2145,  0.2145,  0.2145],\n",
       "        [ 0.8186,  0.8186,  0.8186],\n",
       "        [-0.7653, -0.7653, -0.7653],\n",
       "        [-0.5285, -0.5285, -0.5285],\n",
       "        [-0.4885, -0.4885, -0.4885],\n",
       "        [-0.4749, -0.4749, -0.4749],\n",
       "        [-0.5046, -0.5046, -0.5046],\n",
       "        [-0.4980, -0.4980, -0.4980],\n",
       "        [-0.4526, -0.4526, -0.4526],\n",
       "        [-0.4832, -0.4832, -0.4832],\n",
       "        [-0.4886, -0.4886, -0.4886],\n",
       "        [-0.5064, -0.5064, -0.5064],\n",
       "        [ 0.0306, -0.0225, -0.4840],\n",
       "        [ 0.9728, -0.7984, -0.5043],\n",
       "        [-0.2703,  0.9867, -0.4790],\n",
       "        [-0.6535, -0.5135,  0.9734],\n",
       "        [-0.2495, -0.7673, -0.5314],\n",
       "        [-0.9050, -0.4934, -0.9997],\n",
       "        [-0.3720, -0.2547, -0.5098],\n",
       "        [-0.9797, -0.3759, -0.5111],\n",
       "        [-0.5107, -0.9340,  0.2366],\n",
       "        [-0.5114,  0.0886, -0.3183],\n",
       "        [-0.4964, -0.9349, -0.3444],\n",
       "        [-0.5025, -0.8687, -0.7872],\n",
       "        [-0.3419, -0.4100, -0.5042],\n",
       "        [-0.3897, -0.6474, -0.5052],\n",
       "        [-0.4943, -0.3577, -0.5037],\n",
       "        [-0.5740, -0.4116, -0.5066],\n",
       "        [-0.5734, -0.3651, -0.5156],\n",
       "        [-0.5457, -0.3501, -0.5068],\n",
       "        [-0.6519, -0.3841, -0.5035],\n",
       "        [-0.6654, -0.4123, -0.5085],\n",
       "        [-0.5730, -0.4289, -0.4511],\n",
       "        [-0.5783, -0.8988, -0.5060]], dtype=torch.float64)"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_baxus_target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "state.new_bins_on_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "len() of a 0-d tensor",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[52], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m S, X_baxus_target \u001b[39m=\u001b[39m increase_embedding_and_observations(\n\u001b[1;32m      2\u001b[0m                 S, X_baxus_target, \u001b[39m4\u001b[39;49m, \u001b[39m#state.new_bins_on_split\u001b[39;49;00m\n\u001b[1;32m      3\u001b[0m             )\n",
      "Cell \u001b[0;32mIn[7], line 17\u001b[0m, in \u001b[0;36mincrease_embedding_and_observations\u001b[0;34m(S, X, n_new_bins)\u001b[0m\n\u001b[1;32m     12\u001b[0m idxs_non_zero \u001b[39m=\u001b[39m idxs_non_zero[torch\u001b[39m.\u001b[39mrandperm(\u001b[39mlen\u001b[39m(idxs_non_zero))]\u001b[39m.\u001b[39msqueeze()\n\u001b[1;32m     14\u001b[0m non_zero_elements \u001b[39m=\u001b[39m row[idxs_non_zero]\u001b[39m.\u001b[39msqueeze()\n\u001b[1;32m     16\u001b[0m n_row_bins \u001b[39m=\u001b[39m \u001b[39mmin\u001b[39m(\n\u001b[0;32m---> 17\u001b[0m     n_new_bins, \u001b[39mlen\u001b[39;49m(idxs_non_zero)\n\u001b[1;32m     18\u001b[0m )  \u001b[39m# number of new bins is always less or equal than the contributing input dims in the row minus one\u001b[39;00m\n\u001b[1;32m     20\u001b[0m new_bins \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39mtensor_split(idxs_non_zero, n_row_bins)[\n\u001b[1;32m     21\u001b[0m     \u001b[39m1\u001b[39m:\n\u001b[1;32m     22\u001b[0m ]  \u001b[39m# the dims in the first bin won't be moved\u001b[39;00m\n\u001b[1;32m     23\u001b[0m elements_to_move \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39mtensor_split(non_zero_elements, n_row_bins)[\u001b[39m1\u001b[39m:]\n",
      "File \u001b[0;32m~/anaconda3/envs/BoTorch/lib/python3.9/site-packages/torch/_tensor.py:894\u001b[0m, in \u001b[0;36mTensor.__len__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    892\u001b[0m     \u001b[39mreturn\u001b[39;00m handle_torch_function(Tensor\u001b[39m.\u001b[39m\u001b[39m__len__\u001b[39m, (\u001b[39mself\u001b[39m,), \u001b[39mself\u001b[39m)\n\u001b[1;32m    893\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdim() \u001b[39m==\u001b[39m \u001b[39m0\u001b[39m:\n\u001b[0;32m--> 894\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mTypeError\u001b[39;00m(\u001b[39m\"\u001b[39m\u001b[39mlen() of a 0-d tensor\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m    895\u001b[0m \u001b[39mif\u001b[39;00m torch\u001b[39m.\u001b[39m_C\u001b[39m.\u001b[39m_get_tracing_state():\n\u001b[1;32m    896\u001b[0m     warnings\u001b[39m.\u001b[39mwarn(\n\u001b[1;32m    897\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mUsing len to get tensor shape might cause the trace to be incorrect. \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    898\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mRecommended usage would be tensor.shape[0]. \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    902\u001b[0m         stacklevel\u001b[39m=\u001b[39m\u001b[39m2\u001b[39m,\n\u001b[1;32m    903\u001b[0m     )\n",
      "\u001b[0;31mTypeError\u001b[0m: len() of a 0-d tensor"
     ]
    }
   ],
   "source": [
    "S, X_baxus_target = increase_embedding_and_observations(\n",
    "                S, X_baxus_target, 4, #state.new_bins_on_split\n",
    "            )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.concat(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[tensor([[ 1., -1., -1.,  1.]], dtype=torch.float64),\n",
       " tensor([[ 1., -1., -1.,  1.]], dtype=torch.float64),\n",
       " tensor([[ 1., -1., -1.,  1.]], dtype=torch.float64),\n",
       " tensor([[ 1., -1., -1.,  1.]], dtype=torch.float64),\n",
       " tensor([[ 1., -1., -1.,  1.]], dtype=torch.float64),\n",
       " tensor([[ 1., -1., -1.,  1.]], dtype=torch.float64),\n",
       " tensor([[ 1., -1., -1.,  1.]], dtype=torch.float64),\n",
       " tensor([[ 1., -1., -1.,  1.]], dtype=torch.float64),\n",
       " tensor([[ 1., -1., -1.,  1.]], dtype=torch.float64),\n",
       " tensor([[ 1., -1., -1.,  1.]], dtype=torch.float64),\n",
       " tensor([[ 1.,  0.,  0.,  1.],\n",
       "         [ 0., -1.,  0.,  0.],\n",
       "         [ 0.,  0., -1.,  0.]], dtype=torch.float64),\n",
       " tensor([[ 1.,  0.,  0.,  1.],\n",
       "         [ 0., -1.,  0.,  0.],\n",
       "         [ 0.,  0., -1.,  0.]], dtype=torch.float64),\n",
       " tensor([[ 1.,  0.,  0.,  1.],\n",
       "         [ 0., -1.,  0.,  0.],\n",
       "         [ 0.,  0., -1.,  0.]], dtype=torch.float64),\n",
       " tensor([[ 1.,  0.,  0.,  1.],\n",
       "         [ 0., -1.,  0.,  0.],\n",
       "         [ 0.,  0., -1.,  0.]], dtype=torch.float64),\n",
       " tensor([[ 1.,  0.,  0.,  1.],\n",
       "         [ 0., -1.,  0.,  0.],\n",
       "         [ 0.,  0., -1.,  0.]], dtype=torch.float64),\n",
       " tensor([[ 1.,  0.,  0.,  1.],\n",
       "         [ 0., -1.,  0.,  0.],\n",
       "         [ 0.,  0., -1.,  0.]], dtype=torch.float64),\n",
       " tensor([[ 1.,  0.,  0.,  1.],\n",
       "         [ 0., -1.,  0.,  0.],\n",
       "         [ 0.,  0., -1.,  0.]], dtype=torch.float64),\n",
       " tensor([[ 1.,  0.,  0.,  1.],\n",
       "         [ 0., -1.,  0.,  0.],\n",
       "         [ 0.,  0., -1.,  0.]], dtype=torch.float64),\n",
       " tensor([[ 1.,  0.,  0.,  1.],\n",
       "         [ 0., -1.,  0.,  0.],\n",
       "         [ 0.,  0., -1.,  0.]], dtype=torch.float64),\n",
       " tensor([[ 1.,  0.,  0.,  1.],\n",
       "         [ 0., -1.,  0.,  0.],\n",
       "         [ 0.,  0., -1.,  0.]], dtype=torch.float64),\n",
       " tensor([[ 1.,  0.,  0.,  1.],\n",
       "         [ 0., -1.,  0.,  0.],\n",
       "         [ 0.,  0., -1.,  0.]], dtype=torch.float64),\n",
       " tensor([[ 1.,  0.,  0.,  1.],\n",
       "         [ 0., -1.,  0.,  0.],\n",
       "         [ 0.,  0., -1.,  0.]], dtype=torch.float64),\n",
       " tensor([[ 1.,  0.,  0.,  1.],\n",
       "         [ 0., -1.,  0.,  0.],\n",
       "         [ 0.,  0., -1.,  0.]], dtype=torch.float64),\n",
       " tensor([[ 1.,  0.,  0.,  1.],\n",
       "         [ 0., -1.,  0.,  0.],\n",
       "         [ 0.,  0., -1.,  0.]], dtype=torch.float64),\n",
       " tensor([[ 1.,  0.,  0.,  1.],\n",
       "         [ 0., -1.,  0.,  0.],\n",
       "         [ 0.,  0., -1.,  0.]], dtype=torch.float64),\n",
       " tensor([[ 1.,  0.,  0.,  1.],\n",
       "         [ 0., -1.,  0.,  0.],\n",
       "         [ 0.,  0., -1.,  0.]], dtype=torch.float64),\n",
       " tensor([[ 1.,  0.,  0.,  1.],\n",
       "         [ 0., -1.,  0.,  0.],\n",
       "         [ 0.,  0., -1.,  0.]], dtype=torch.float64),\n",
       " tensor([[ 1.,  0.,  0.,  1.],\n",
       "         [ 0., -1.,  0.,  0.],\n",
       "         [ 0.,  0., -1.,  0.]], dtype=torch.float64),\n",
       " tensor([[ 1.,  0.,  0.,  1.],\n",
       "         [ 0., -1.,  0.,  0.],\n",
       "         [ 0.,  0., -1.,  0.]], dtype=torch.float64),\n",
       " tensor([[ 1.,  0.,  0.,  1.],\n",
       "         [ 0., -1.,  0.,  0.],\n",
       "         [ 0.,  0., -1.,  0.]], dtype=torch.float64),\n",
       " tensor([[ 1.,  0.,  0.,  1.],\n",
       "         [ 0., -1.,  0.,  0.],\n",
       "         [ 0.,  0., -1.,  0.]], dtype=torch.float64),\n",
       " tensor([[ 1.,  0.,  0.,  1.],\n",
       "         [ 0., -1.,  0.,  0.],\n",
       "         [ 0.,  0., -1.,  0.]], dtype=torch.float64)]"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "S_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>x1</th>\n",
       "      <th>x2</th>\n",
       "      <th>x3</th>\n",
       "      <th>x4</th>\n",
       "      <th>loss_estimate</th>\n",
       "      <th>iter</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>547.541934</td>\n",
       "      <td>852.458066</td>\n",
       "      <td>852.458066</td>\n",
       "      <td>547.541934</td>\n",
       "      <td>0.006947</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>548.606921</td>\n",
       "      <td>851.393079</td>\n",
       "      <td>851.393079</td>\n",
       "      <td>548.606921</td>\n",
       "      <td>0.006550</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>548.074361</td>\n",
       "      <td>851.925639</td>\n",
       "      <td>851.925639</td>\n",
       "      <td>548.074361</td>\n",
       "      <td>0.006550</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>551.696953</td>\n",
       "      <td>807.304696</td>\n",
       "      <td>851.103226</td>\n",
       "      <td>551.696953</td>\n",
       "      <td>0.007323</td>\n",
       "      <td>24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>527.814025</td>\n",
       "      <td>823.478848</td>\n",
       "      <td>851.986618</td>\n",
       "      <td>527.814025</td>\n",
       "      <td>0.002031</td>\n",
       "      <td>25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>526.521650</td>\n",
       "      <td>969.644809</td>\n",
       "      <td>851.810697</td>\n",
       "      <td>526.521650</td>\n",
       "      <td>0.006550</td>\n",
       "      <td>31</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           x1          x2          x3          x4  loss_estimate  iter\n",
       "0  547.541934  852.458066  852.458066  547.541934       0.006947     0\n",
       "0  548.606921  851.393079  851.393079  548.606921       0.006550     4\n",
       "0  548.074361  851.925639  851.925639  548.074361       0.006550     9\n",
       "0  551.696953  807.304696  851.103226  551.696953       0.007323    24\n",
       "0  527.814025  823.478848  851.986618  527.814025       0.002031    25\n",
       "0  526.521650  969.644809  851.810697  526.521650       0.006550    31"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_plot = df.query('iter>0')\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "x = df_plot['iter']\n",
    "y = df_plot['loss_estimate']\n",
    "\n",
    "plt.plot(x, best_value)\n",
    "#plt.legend(title='Parameter where:')\n",
    "plt.show()\n",
    "df.query('loss_estimate<0.010')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv(\"./data/baxus.csv\",index = None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
